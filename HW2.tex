\documentclass[11pt]{article}

\newcommand{\numpy}{{\tt numpy}}    % tt font for numpy

\topmargin -.5in
\textheight 9in
\oddsidemargin -.25in
\evensidemargin -.25in
\textwidth 7in
\renewcommand{\baselinestretch}{1.25} 

% psudo-code text
\usepackage{algpseudocode}
\usepackage{aligned-overset}

\usepackage{setspace}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}


\begin{document}

% ========== Edit your name here
\author{Ido Frankel - 318985108}
\title{Distributed Graph Algorithms HW 2}
\maketitle

\medskip

% ========== Begin answering questions here

\section{Exercise 1}
For each component $P_i$:
\begin{algorithmic}[1]
\State pick a leader and build a BFS tree from it
\State count $\leftarrow$ number of vertices in the tree.
\If{count $ < \sqrt{n}$}
    \State set $H_i \leftarrow \emptyset$
\Else
    \State set $H_i \leftarrow E \backslash E_{P_{i}}$
\EndIf
\end{algorithmic}

\subsubsection*{Note about the BFS tree and calculation}
I use the BFS algorithm shown in class as a black box, with one minor change. after each node updates within itself its parent node, it also sends an ACK message to the parent, notifying that the edge is indeed part of the BFS tree. (I asked if it is allowed in a reception hour)
In addition the amount of vertices in the trees, can be computed as follows: all the leaves in the tree send a message to their parents in the tree, which then accumulate the number of messages from their children, and send it to their parent ( $+1$ for themselves), until it reaches the root.

\subsection*{Correctness}

\begin{lemma}
\label{parts_bound_amount}
There at most $\sqrt{n} -1 $ parts with more than $\sqrt{n}$ vertices each.
\end{lemma}
Let us assume by contradiction that there are at least $\sqrt{n}$ with more than $\sqrt{n}$ vertices. then, the total number of vertices in the graph is at least $\sqrt{n} * (\sqrt{n} +1 )= n + \sqrt{n} > n$. Contrary to the fact that the total number of vertices is $n$

\begin{lemma}
\label{parts_dimater_D}
each part with {\Large V}$(G[P_i]) > \sqrt{n}$ vertices holds that the diameter of $G[P_i] \cup H_i$ is $D$
\end{lemma}
According to the algorithm, if the part has more than $\sqrt{n}$ vertices, $G[P_i] \cup H_i = G$, because each edge that is not part of $H_i$, is part of $G_{P_{i}}$ according to the algorithm. Therefore, the diameter of $G[P_i] \cup H_i$ is $D$.

\begin{lemma}
\label{parts_dimater_sqrt_n}
each part with {\Large V}$(G[P_i]) \le \sqrt{n}$ vertices, holds that the diameter of $G[P_i] \cup H_i$ is at most $\sqrt{n}$
\end{lemma}
The diameter of every connected graph is upper bounded by the number of vertices in the graph. Assume by contradiction that it is false, then there are two vertices which their shortest path between them is at least $\sqrt{n} +1$, dividing to cases:
\begin{itemize}
    \item The path has more than $\sqrt{n}$ unique vertices, which is a contradiction to the fact that $G$ has fewer vertices than that
    \item The path has less or equal to $\sqrt{n}$ unique vertices, then according to the pigeonhole theorem there is a vertex that appears twice in the path (meaning there is a cycle), a contradiction to the fact that it is the shortest path. 
\end{itemize}


\begin{lemma}
\label{edges_bound}
Each edge appears in at most $\sqrt{n}$ of the sub-graphs $G[P_i] \cup H_i$
\end{lemma}
According to the lemma \ref{parts_bound_amount}, there are at most $\sqrt{n} -1$ parts with more than $\sqrt{n}$ vertices. According to the algorithm, it means that there are at most $\sqrt{n}-1$ non-empty $H_i$. Furthermore, each edge in the graph can belong to at most one $G[P_i]$, that is, if both of its touching vertices are part of $G[P_i]$, otherwise it will not belong to any $G[P_i]$.
In total, each edge will be part of at most $\sqrt{n}$ of the sub-graphs $G[P_i] \cup H_i$

\begin{lemma} The algorithm computes $(\sqrt{n}, O(D + \sqrt{n}) )$ shortcut
\end{lemma}
Whether the part have strictly more than $\sqrt{n}$ vertices, or not, according to lemmas \ref{parts_dimater_D} and \ref{parts_dimater_sqrt_n}, its diameter is upper bounded by $D$ and $\sqrt{n}$ respectively. This implies that $O(\sqrt{n} +D)$ is an upper bound of the diameter of each part. According to lemma \ref{edges_bound}, each edge appears at $\sqrt{n}$ of the sub-graphs $G[P_i] \cup H_i$. Therefore, the algorithm successfully computes the desired shortcut.

$\newline$
Note: The calculation of each $H_i$ is done in parallel. Since each part $P_i$ is disjoint in node with all other parts, there is no edge between $P_i$ and $P_j$. i.e., each message sent by the vertex in $P_i$ stays within the component. Hence calculation of different parts can be achieved in parallel.

\subsection*{Complexity}
\begin{enumerate}
    \item The process of picking a leader and the construction of a BFS tree, as taught in class is O(D). It takes $O(D)$ rounds for each message that $v$ sends to reach the furthest node in the tree (since the Diameter is D). 
    \item The calculation of number of vertices in each BFS tree is $O(D)$ as we have showed in previous exercise. (each leaf sends ACK to root, and each vertices accumulate the amount sent by its children, and pass it to to root, (including itself)).
    \item The calculation of the $H_i$ set, given the variable $count$ is done in $O(1)$.
\end{enumerate}
Total: $O(D)$

%\pagebreak%
\section{Exercise 2}
\begin{algorithmic}[1]
\State initialize $C_i = {v_i}$ (each vertex as a separate component)
    \While{There are outgoing edges from component $C$}
    \State $\forall C, \forall v\in C$, $v$ sends to all its neighbours an outgoing edge (which belongs to $H$) from $C$.
    \State All vertices send all their neighbors in $C$, one outgoing edge from $C$ (via the network graph)
    \State compute maximal matching on outgoing edges that belongs to $H$
    \State Merge components adjacent to the edges of the matching
    \State Merge neighboring unmatched components that do not have adjacent edge in the matching
    \State in each merge of components $C_1, C_2$, the vertices adjacent to the selected edge (which caused the merge), learns the minimal ID of the components and then sends it to all vertices in $C_1, C_2$
    \EndWhile
\end{algorithmic}

\subsection*{Correctness}
\begin{lemma}
After O(1) rounds, all vertices of $C$ learn the outgoing edge from $C$ 
\end{lemma}
Each vertex sends one message to each neighbor, which in turn locally computes one edge (that is, an edge =$(u,v)$ with decreasing id of $u,v$) from the input it receives and then sends one message to all its neighbors in $C$ with that edge.
Because the diameter of the network graph is 2, then in $O(1)$ rounds, each vertex in $C$ knows which outgoing edge was picked.

\begin{lemma}
calculation of outgoing edge from each component is done in parallel
\end{lemma}
Each vertex in $C$ sends one message to all of its neighbors, later, each vertex sends a single message to any neighboring vertex in $C$. i.e., different components received the messages on different edges. And only one message is sent on each edge (in each direction). 

\begin{lemma}
\label{message_transfer_2_rounds}
A vertex can send a message to all of the component's vertices in 2 rounds.
\end{lemma}
Similarly to the calculation of the outgoing edge, the vertex sends all its neighbors the message, and then the neighbors themselves transmit this message to their neighbors in $C$ (each edge transfers at most 1 message in each direction).

\begin{lemma}
After the merge it takes $O(1)$ rounds for all the vertices in the merged component to learn the new ID.
\end{lemma}
According to the lemma \ref{message_transfer_2_rounds}, the adjacent vertices of the merged edge can send the new chosen ID in 2 rounds.

\begin{lemma}
The Algorithm computes the connected components of $G_H$
\end{lemma}
At each iteration, the algorithm merges components that have a connected edge of $H$. meaning ,we merge only connected components under $G_H$. In addition, the algorithm stops only when there are no outgoing edges from all components. Therefore, the algorithm stops when each component contains all connected vertices in $G$ under $H$

\subsection*{Complexity}
\begin{itemize}
    \item In each iteration, the number of connected components is reduced by at least half, as each component is merged with at least one component. Therefore, there are at most $\log{n}$ iterations.
    \item In each iteration, the calculation of maximal matching takes $O(\log^{*}{n})$
    \item The broadcast of the new component ID, to all vertices of the merged component takes $O(1)$
    \item The calculation of the selected outgoing edge takes $O(1)$
\end{itemize}
The algorithm takes $O(\log{n} \cdot \log^{*}{n})$ rounds.

\section{Exercise 3}

\subsection{}
Assume by contradiction that there exists an induce graph $G[V_i]$ that has a vertex of degree greater than $t$. According to the definition of the induced graph, it means $v$ have more than $t$ vertices with same color as $v$ in $G[V_i]$. Meaning $\phi$ is not a valid $t$-defective $k$-coloring function.

\subsection{}

\subsubsection*{Correctness of $t + \frac{\Delta}{p}-$defective $p^2$ coloring}

\begin{lemma}
\label{psi_p2_coloring}
$\psi$ is $p^2$ coloring function.
\end{lemma}
$\psi$ consists as a concatenation of $\psi_1, \psi_2$, each $p-$coloring function. meaning, the output of $\psi(u)$ is a color, which can decoded in $\log{p}$ bits. Therefore, $\psi$ outputs a color that can be decoded by $2*\log{p}=\log{p^2}$ bits. There are $2^{\log{p^2}}=p^2$ options. Therefore, $\psi$ is the $p^2$ coloring function. 


% \begin{lemma}
% \label{psi_1_2_delta_defective}

% % DELETE THIS 
% % $\forall v$, $v$ has at most $\frac{|S(v)|}{p}$ and $\frac{|G(v)|}{p}$ neighbors with same $\psi_1, \psi_2$ color as itself respectively. 

% $\forall v$, $v$ has at most $\frac{\Delta}{p}$ neighbors with same $\psi_1$ or $\psi_2$ color as itself respectively. 
% \end{lemma}
% proof for $\psi_1$, the proof of $\psi_2$ is identical. \\
% Be $v$ a vertex with degree $\Delta_v$. 

% Because each vertex chooses $\psi_1$ to be the color used the least by its neighbors, there are at most $\frac{|S(v)|}{p}$ neighbors (which belongs to $S(v)$) with the same $\psi_1$ color as $v$ according to the pigeon hole principle and due to the fact that we choose the color that is used least by the neighbors. In addition according to the algorithm, all other neighbors $u \in G(v)$, chooses their $\psi_1$ only after $v$ chooses its (according to the algorithm). In the worst case, all $G(v)$ will choose their $\psi_1(u)$ to be the same color as $\psi_1(v)$. Meaning $v$ shares its $\psi_1$ coloring with at most $\frac{|S(v)| + |G(v)|}{p} < \frac{\Delta_v}{p}$ neighbours which belongs to 
% $S(V) \cup G(v)$,


% (and it is upper bound by $\frac{\Delta}{p}$ where $\Delta$ is the maximal degree in the graph).


% proof for $\psi_1$, the proof of $\psi_2$ is identical. \\
% Be $v$ a vertex with degree $\Delta_v$. Because each vertex chooses $\psi_1$ to be the color used the least by its neighbors, there are at most $\frac{\Delta_v}{p}$ neighbors with the same $\psi_1$ color as $v$ according to the pigeon hole principle and due to the fact that we choose the color that is used least by the neighbors (and it is upper bound by $\frac{\Delta}{p}$ where $\Delta$ is the maximal degree in the graph).

% \begin{lemma}
% \label{psi_1_2_t_defective}
% $\forall u$, neighbor of $v$ with the same color as $v$ The selection of $\psi_1(u),\psi_2(u)$ is independent of the selection of $\psi_1(v),\psi_2(v)$
% \end{lemma}
% Denote $N_{\phi(v)}(v)= \left\{ u \mid u \in N(v) \land \phi(v) = \phi(u) \right\}$. \\
% Let $u \in N_{\phi(v)}(v)$. Since $u$ and $v$ have the same color, this means that $u \notin S(v) \land v \notin S(u)$ and $u \notin G(v) \land v \notin G(u)$. meaning that according to the algorithm, $u$ chooses $\psi_1$ without taking into account $\psi_1(v)$. meaning $u,v$ chooses $\psi_1, \psi_2$ independently of each other.

% \begin{lemma}
% \label{psi_defective}
% $\psi$ is $t+\frac{\Delta}{p}$-defective
% \end{lemma}
% Divide into cases.
% \begin{itemize}
%     \item $\forall u\in N_{\phi(v)}(v)$: According to lemma \ref{psi_1_2_t_defective}, $v$ picks $\psi_1(v), \psi_2(v)$ independently to $u$. \\ in the worst case, $v$ can share its $\psi(v)$ color with all $t$ described neighbors of his that have the same color as his.
%     \item $u \in N(v) \backslash N_{\phi(v)}(v)$:  according to lemma \ref{psi_1_2_delta_defective}, $v$ can share $\psi_1, \psi_2$ with at most $\frac{\Delta}{p}$ neighbors. because $\psi$ is a concatenation of $\psi_1, \psi_2$. $v$ shares both $\psi_1$ and $\psi_2$ with at most $\frac{\Delta}{p}$ neighbors, meaning it shares $\psi$ with at most $\frac{\Delta}{p}$ neighbors (which do not have the same $\phi$ color as $v$)
% \end{itemize}
% To conclude, in the worst case, $v$ shares its color with at most other $t + \frac{\Delta}{p}$ neighbors.



% ======================= NEW ============
% ==================== NEW ===============
% \begin{lemma}
% \label{psi_defective_2}
% $\psi$ is $t+\frac{\Delta}{p}$-defective
% \end{lemma}
% We will divide the proof to two extreme cases, and showing the requested defecting to both cases.
% Denote $N_{\phi(v)}(v)= \left\{ u \mid u \in N(v) \land \phi(v) = \phi(u) \right\}$. \\
% \begin{itemize}
%     \item \underline{none of $N_{\phi(v)}$ have choose either $\psi_1$ or $\psi_2$}: then $v$ shares its $\psi_1$ color with at most $\frac{|S(v)|}{p}$ vertices. (because $N_{\phi(v)}$ haven't picked $\psi_1$ yet, and all of $G(v)$ vertices, waits for $v$ to pick its $\psi_1$ first, according to the algorithm). In a similar way, $v$ shares its $\psi_2$ color with at most $\frac{|G(v)|}{p}$ vertices. In addition, in the worst case, all of its neighbors in $N_{\phi(v)}$, can pick the same $\psi$ color as $v$, Hence in total,
%     In the worst case $v$ shares its $\psi$ color with $\frac{|S(v)|+|G(v)|}{p} + t $ vertices, meaning $\psi$ is $\frac{(|S(v)|+|G(v)|}{p} + t)$-defective, and in particular it means that $\psi$ is $(\frac{\Delta}{p} + t)$-defective
    
%     \item \underline{all of $N_{\phi(v)}$ have choose both $\psi_1$ and $\psi_2$}: then $v$ shares its $\psi_1$ color with at most $\frac{|S(v)+t|}{p}$ vertices (because all of $G(v)$ vertices, waits for $v$ to pick its $\psi_1$ first, according to the algorithm). In a similar way  $v$ shares its $\psi_2$ color with at most $\frac{|G(v)+t|}{p}$ vertices. Hence in total,
%     In the worst case $v$ shares its $\psi$ color with $\frac{|S(v)|+|G(v)|}{p} + \frac{2t}{p}$, vertices. which means in particular that $\phi$ is $(\frac{\Delta}{p} + t)$-defective (because $p \ge 2$ which yields $\frac{2t}{p} < t$).
% \end{itemize}
% We have shown that in both cases $\psi$ is  $t+\frac{\Delta}{p}$-defective. 

\begin{lemma}
\label{psi_defective_3}
$\psi$ is $t+\frac{\Delta}{p}$-defective
\end{lemma}
First, we will present few notations which will be useful. \\
Denote $N_{\phi(v)}(v)= \left\{ u \mid u \in N(v) \land \phi(v) = \phi(u) \right\}$. \\
Denote $A = \{ u \in N_{\phi(v)}(v) \mid \text{u has choose } \psi_1 \}$, let $k_1 = |A|$ \\
Denote $B = \{ u \in N_{\phi(v)}(v) \mid \text{u has choose } \psi_2 \}$, let $k_2 = |B|$ \\
Denote $C = $\overline{A \cup B}$ (Note $0 \le |C| \le t$), let $k_3 = |C| $

According to the inclusion-exclusion principle, the number of vertices of $N_{\phi(v)}(v)$ which have not choose either $\psi_1$ or $\psi_2$ is $k_3 = t - |A \cup B| = t - |A| - |B| + |A \cap B| = t - (k_1 + k_2) + |A \cap B|$.
Hence, According to the algorithm and the pigeon hole theorem
\begin{itemize}
    \item the total number of vertices which can share $\psi_1(v)$ is $\frac{|S(v)| + k_1}{p}$
    \item the total number of vertices which can share $\psi_2(v)$ is $\frac{|G(v)| + k_2}{p}$
    \item the total number of vertices which have not choose any $\psi_1, \psi_2$ is $k_3$
\end{itemize}
lets define $\psi(v) = \psi_1(v), \psi_2(v)$. In the worst case, any vertex $u$ which share $\psi_1$ color with $v$, also shares its $\psi_2$ color, similarly any vertex $x$ which share $\psi_2$ color with $v$, also shares its $\psi_1$ color. In addition in the worst case each vertex $u \in C$ can choose $\psi(v)$ as their color. \\
To conclude, in the worst case there exists at most 
\begin{doublespacing}
\newline
$\frac{|S(v)| + k_1}{p} + \frac{|G(v)| + k_2}{p} + k_3 =$
\\[5mm]
$\frac{|S(v)| + |G(v)|}{p} + \frac{k_1 + k_2}{p} + (t - k_1 - k_2 +  |A \cap B|) =$ 
\\[5mm] 
$\frac{|S(v)| + |G(v) +t }{p} - \frac{t}{p} + \frac{k_1 + k_2}{p} + (t - k_1 - k_2 +  |A \cap B|) =$
\\[5mm]
$\frac{\Delta}{p} + t + \frac{k_1 + k_2 - p*k_1 - p*k_2 - t + p * |A \cap B|}{p}  = $
\\[5mm]
$\frac{\Delta}{p} + t + \frac{k_1(1-p) + k_2(1-p) - t + p * |A \cap B|}{p} \underbrace{\le}_{|A \cap B| \le \min({k_1, k_2}), \text{ w.l.o.g } |A \cap B| \le k_1}$
\\[5mm]  
$\frac{\Delta}{p} + t + \frac{k_1(1-p) + k_2(1-p) - t + p * k_1}{p} =  \frac{\Delta}{p} + t + \frac{1}{p}*(\underbrace{k_1 - t}_{\le 0} + \underbrace{k_2(1-p)}_{\le 0}) \le  \boxed{\frac{\Delta}{p} + t}$
\end{doublespacing}


meaning, that in the worst case $v$ shares its $\psi$ color with at most $\frac{\Delta}{p} + t$ of its neighbours


\begin{lemma}
$\psi$ is $t+\frac{\Delta}{p}$-defective $p^2$-coloring.
\end{lemma}
According to Lemma \ref{psi_defective_3} and Lemma \ref{psi_p2_coloring}

\subsubsection*{Complexity claims}

\begin{lemma}
\label{psi_1_rounds}
It takes $O(\phi(v) -1)$ rounds for $v$ to choose $\psi_1{v}$
\end{lemma}
proof by induction: 

\textbf{Base}: for $\phi(v)=1$ it takes at most 0 rounds to choose $\psi_1(v)$
because there is no vertex $u$ with $\phi(u) < \phi(v)$, then by definition $S(v)=\emptyset$. Therefore, $v$ can choose $\psi_1(v)$ without the need to wait for the response of other vertices.

\textbf{Induction hypothesis}: for $\psi(v)=l-1$ it takes at most $l-2$ rounds to choose $\psi_1(v)$

\textbf{Induction step}: According to the induction hypothesis, all nodes with $\phi(u)=l-1$ can choose $\psi_1(u)$ in at most $l-2$ rounds. Let $v$ be a vertex with color $\phi(v)=l$. then, after at most $l-2$ rounds, all $S(v)$ compute their $\psi_1$ color. It takes another round, for them to send $v$ their $\psi_1$ color. Therefore, after at most $l-1$ rounds, $v$ can locally compute $\psi_1$

\begin{lemma}
\label{psi_2_rounds}
It takes $O(k -\phi(v) -1 )$ rounds for $v$ to choose $\psi_2(v)$
\end{lemma}
similar proof to \ref{psi_1_rounds} (descending induction) as such, I will skip it. (Please do not kill me :) )

\begin{lemma}
\label{psi_rounds}
It takes $O(k)$ rounds for $v$ to choose $\psi(v)$
\end{lemma}
By Lemmas \ref{psi_1_rounds} and \ref{psi_2_rounds}, it takes $O(\phi(v))$, $O(k- \phi(v))$  rounds to calculate $\psi_1(v)$ and $\psi_2(v)$ respectively. Because $v$ needs both $\psi_1, \psi_2$ in order to determine $\psi$, it takes \\
$\max \left\{ O(\phi(v)), O(k- \phi(v)) \right\}$
% $\max \left\{ {O(\phi(v)), O(k- \phi(v)) }\right\}$
rounds, which is equivalent to $O(\phi(v) + k- \phi(v))=O(k)$ rounds.


\subsubsection*{Complexity calculation}
\begin{itemize}
    \item Sending a message of length $\log{k}$ (where $k \le n$) to all neighbors takes a single round
    \item computing $S(v), G(v)$ which can be done locally takes 0 rounds.
    \item Choosing $\psi_1(v), \psi_2(v)$ takes $O(k)$ rounds according Lemma \ref{psi_rounds}
    \item Step 5 is done locally, takes at most a single round.
\end{itemize}
Total: $O(k)$


\subsection{}

\begin{algorithmic}[1]
\State Use $\mathcal{A}_1$ to compute a $\frac{\Delta}{\log{\Delta}}-$defective $(\log^2{\Delta})$ coloring.
\For{$i=0 \: ; \: i < \log^2(\Delta) \: ; \: i++ $}
    \State Apply $\mathcal{A}_2$ on $G[V_i]$ ($G[v_i]$ consists same color-vertices as defined in exercise 3.1) in order to compute a legal $O(\frac{\Delta}{\log{\Delta}})$ coloring.
\EndFor

\State Set unique color for each induced graph $G[V_i]$

% \State Use the iterate color reduction algorithm from the lecture.

\State Apply the parallel color reduction algorithm from the tutorial.

\end{algorithmic}

\subsubsection*{Correctness}

\begin{lemma}
Calculation of algorithm $\mathcal{A}_2$ on each induced graph takes $T_2(\frac{\Delta}{\log{\Delta}})$ rounds
\end{lemma}
Algorithm $\mathcal{A}_1$ computes a $\frac{\Delta}{\log{\Delta}}$ defective coloring function, according to exercise $3.1$ it implies that each induced graph $G[V_i]$ has maximal degree of $\frac{\Delta}{\log{\Delta}}$. As such algorithm $\mathcal{A}_2$ computes on each induced graph a valid $O(\frac{\Delta}{\log{\Delta}})$ in $T_2(\frac{\Delta}{\log{\Delta}})$ rounds according to its definition.

\begin{lemma}
\label{A_2_parallel}
The calculation of $\mathcal{A}_2$ on each induced graph can be done in parallel
\end{lemma}
Because each induced graph includes only vertices of same color, it means, there is not a vertex which is part of two $G[V_i], G[V_j]$. Hence, every induced graph is disjoint with all others. Meaning, the application of $\mathcal{A}_2$ can be done in parallel, and during the execution of the algorithm, there is no message which is sent from one induced graph to another.

\begin{lemma}
In step $5$ we defined a $0-$defective $O(\Delta*\log{\Delta})$ coloring for $G$
\end{lemma}
After application of algorithm $\mathcal{A}_2$, each induced graph has valid $O(\frac{\Delta}{\log{\Delta}})$ coloring function by definition (denote $\varphi_i)$. In step 5, we set a unique color scheme for each of the $\log^2{\Delta}$ induced graphs, it means every two induced graphs do not share any color. Hence we can construct a  $0-$defective $O(\frac{\Delta}{\log{\Delta}} * \log^2{\Delta})
=O(\Delta * \log{\Delta})$-coloring function of $G$ as follows: $\forall v \in G$ if $v \in V_i$, set $\Phi(v) = \varphi_i(v)$. 
\begin{lemma}
\label{parallel_reduction_tutorial}
The parallel color reduction algorithm from the tutorial, which preforms on graph with maximal degree $\Delta$ with given $O(\Delta * \log{\Delta})$ coloring function $\Phi$ takes $O(\Delta * \log({\log{\Delta}}))$
\end{lemma}
$\Phi$ is $0-$defective $O(\Delta*\log{\Delta})$ coloring, $G$ has maximal degree of $\Delta$. According to the algorithm presented in the tutorial, Given $\Phi$ we can compute $\Delta+1$ coloring in 
$O(\Delta * \log{\frac{C}{\Delta}})$ where $C$ is the number of colors of $\Phi$, Hence the computation takes $O(\Delta * \log{\frac{\Delta*\log{\Delta}}{\Delta}})=O(\Delta * \log({\log{\Delta}}))
%=O(\Delta * \log{\Delta})
$


\subsubsection*{Complexity}
\begin{itemize}
    \item Step 1 takes $T_1(\Delta)$ rounds
    \item According to lemma \ref{A_2_parallel} Step 2 is calculated on each induced graph in parallel. Hence the for loop is preformed in parallel and takes in total $T_2(\frac{\Delta}{\log{\Delta}})$ rounds. 
    \item Algorithm of step 6 takes $O(\Delta\log{\Delta})$ rounds by Lemma \ref{parallel_reduction_tutorial}
\end{itemize}

Total complexity: $T_1(\Delta) + T_2(\frac{\Delta}{\log{\Delta}}) + O(\Delta * \log({\log{\Delta}}))$ 


\end{document}


